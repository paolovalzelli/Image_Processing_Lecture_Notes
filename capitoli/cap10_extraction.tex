\chapter{Feature Extraction}
\label{ch:extraction}

\section{Representation and Description}

Following image segmentation, objects may require representation and subsequent description.
Two possible representations are:

\begin{itemize}
    \item \textbf{external (boundary)}: The main focus is on shape characteristics.
    A representation is provided by the polygon defining the boundary, whereas a description is based on some of its features, such as length and orientation;
    \item \textbf{internal (regional)}: The main focus is on regional properties.
    Representation and description are based on pixels inside the object.
\end{itemize}

Object representation can compact data in a truthful yet compressed manner.
From this encoded shape, a list of features, properties, and descriptors can be extracted.
A \textbf{descriptor} captures essential differences among distinct objects, making it suitable for classification and ensuring invariance to noise.
\textbf{Feature extraction} allows for the detection and representation of features of interest, marking the transition from pictorial to non-pictorial data representation.
It is usually performed on binary images to retrieve a compact feature vector.

\section{Shape Representation}

If representing an object simply is necessary (e.g., via the enclosing circle or rectangle, or by the boundary or skeleton), utilising descriptors invariant to scale, rotation, and translation may be desirable.
In some contexts, however, rotation and scale can be important; for example, in Optical Character Recognition (OCR).

To achieve \textbf{boundary representation}, the first step in feature extraction, it is necessary to choose a definition of connectivity (4 or 8 neighbours), a starting point, and then describe, through a \textbf{chain code}, the list of specified steps to traverse every pixel of the boundary in a clockwise direction.

\noindent The main problems with this technique are the length of the chain code and its sensitivity to noise.
Both can be addressed by using a larger grid spacing, resulting in a shorter code that is more robust to noise.
Optimal resolution should be chosen according to the case.
The starting point determines the result, but it is possible to treat the code as circular and sort it to retrieve the minimum magnitude integer; thus, the chain code becomes independent of the starting point.
The chain code depends on the rotation of the object boundary; however, it is possible to calculate the \textit{difference code}, which counts the number of direction changes separating two adjacent code elements in the counterclockwise direction.
The final chain code becomes independent of region rotation.

\subsection{Polygonal approximations}

A polygon can approximate a boundary representation, capturing the essence of the object shape with the fewest possible segments.
Approximation is usually achieved through an iterative process, where the main examples are:

\begin{itemize}
    \item \textbf{minimum perimeter polygons (MPP)};
    \item \textbf{merging techniques};
    \item \textbf{splitting techniques}.
\end{itemize}

\subsubsection{Minimum perimeter polygons}

The boundary is covered with cells of a chosen size, and a polygon shrinks to fit inside these cells with the shortest possible perimeter.
Grid size determines the number of segments in the final perimeter; therefore, it must be chosen according to requirements.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\linewidth]{immagini/mpp.png}
    \caption{An object boundary, the cells that enclose it, and its minimum perimeter polygon.}
    \label{fig:mpp}
\end{figure}

\subsubsection{Splitting techniques}

\textbf{Splitting techniques} are iterative processes starting from an initial guess, then calculating the distance from the segment to the centre of each pixel on the boundary.
If this distance exceeds a set threshold, a new vertex is created.
The procedure is repeated until every point meets the criterion.
The only parameter to set with this technique is the distance threshold.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\linewidth]{immagini/splitting.png}
    \caption{Splitting techniques.}
    \label{fig:splitting}
\end{figure}

\subsubsection{Skeletons}

One effective way to compress information regarding object shape without resorting to boundary representation is to use the morphological operation \textbf{skeleton}, which allows for the reduction of the structural shape of a region to a graph.
The resulting curve should be thin, centred, topologically equivalent to the original object, and reversible.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\linewidth]{immagini/skeleton.png}
    \caption{Skeletons of three regions.}
    \label{fig:skeleton}
\end{figure}

\section{Shape Descriptors}

\subsection{Descriptors}

After the representation step, objects need to be described to facilitate later classification.
It is therefore necessary to obtain a list of features compressing information without resorting to a complete description of each object.
\textbf{Descriptors} become labels for objects, serving as inputs for subsequent object classification.
Features can be extracted from both the boundary and the grey levels of pixels in the internal region.

\subsection{Fourier descriptors}

The coordinates of each pixel on the boundary in the $xy$ space become the real and imaginary parts of a complex number, on which it is possible to perform a Fourier transform to generate \textbf{Fourier Descriptors} (FD).
By performing the inverse Fourier transform on a subset of these descriptors, a compressed approximation of the original boundary is retrieved.
For each pixel $k$, the associated complex number is given by:

\begin{equation}
    s(k) = [x(k), y(k)] = x(k) + \iu y(k), \qquad k=0,1,\dots,K-1
\end{equation}

\noindent From the DFT of these complex numbers, the complex Fourier descriptors in frequency space are obtained:

\begin{equation}
    a(u) = \sum_{k=0}^{K-1}s(k)e^{- \dfrac{2 \pi \iu uk}{K}}, \qquad u=0,1,\dots,K-1
\end{equation}

\noindent The original coefficients $s(k)$ are restored through an inverse FT:

\begin{equation}
    s(k) = \frac{1}{K} \sum_{u=0}^{K-1}a(u)e^{\dfrac{2 \pi \iu uk}{K}}, \qquad k=0,1,\dots,K-1
\end{equation}

\noindent An approximate reconstruction can be obtained by a subset of $P$ Fourier coefficients:

\begin{equation}
    \hat{s}(k) = \frac{1}{P} \sum_{u=0}^{P-1}a(u)e^{\dfrac{2 \pi \iu uk}{K}}, \qquad k=0,1,\dots,K-1
\end{equation}

\noindent For $k=0$, $s(k)$ represents the position of the boundary centre.
Each descriptor $a(u)$ describes a feature; therefore, increasing the number of components in the description renders sharper details.
Usually, a small fraction of the original components yields a good reconstruction of the original shape.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\linewidth]{immagini/fourier_descriptors.png}
    \caption{Boundary reconstruction using 546, 110, 56, 28, 14, and 8 Fourier descriptors out of a possible of 1090.}
    \label{fig:fourier_descriptors}
\end{figure}

\subsubsection{Properties of Fourier descriptors}

Fourier transform properties also apply to descriptors:

\begin{itemize}
    \item \textbf{translation}: Translation only affects the first term of the FD; that is, the DC component;
    \item \textbf{scaling}: After scaling, each FD is scaled by the same factor as the original image;
    \item \textbf{rotation}: FDs are invariant under rotation;
    \item \textbf{starting point}: FD magnitude is invariant under a change in the starting point.
\end{itemize}

\subsection{Statistical moments}

In some cases, FDs are not necessary for the required boundary description, and a simpler approach can be followed.
A boundary segment can be considered a distribution if the first and last points lie on the $r$ axis of an arbitrary value.
\textbf{Statistical moments} represent statistical measures of data that can describe useful information about shape.

If $r$ is a random variable and $g(r_i)$ is a normalised distribution, moments are defined by:

\begin{equation}
    \mu_n(r) = \sum_{k=0}^{K-1} (r_i - m)^n g(r_i), \qquad m = \sum_{i=0}^{K-1} r_i g(r_i)
\end{equation}

\noindent Moments come in integer orders:

\begin{itemize}
    \item \textbf{order 0} is the number of points in the data;
    \item \textbf{order 1} is the sum; it is used to find the mean;
    \item \textbf{order 2} is the variance; it describes spread around the mean;
    \item \textbf{order 3} is skewness; it describes symmetry around the mean.
\end{itemize}

\section{Regional Descriptors}

\subsection{Regional features}

\textbf{Regional descriptors} can focus only on boundary pixels, or they can also consider grey levels of pixels in the internal region:

\begin{itemize}
    \item \textbf{area}: Given by the number of pixels in the region;
    \item \textbf{perimeter}: Given by the number of pixels connected to the background;
    \item \textbf{compactness}: Combines area and perimeter, allowing for a basic measurement of roundness $P2A = \dfrac{(2p)^2}{A}$.
    It equals 1 for a circle and is larger for long, thin shapes;
    \item \textbf{circularity ratio}: It also combines area and perimeter; it is equal to 1 for circles and smaller for other shapes $\dfrac{4 \pi A}{(2p)^2}$;
    \item \textbf{grey level measures}: Include the mean, median, minimum, and maximum values.
\end{itemize}

\noindent By combining different regional descriptors, it is possible to differentiate among distinct shape types.

\subsection{Statistical features of texture}

To describe region \textbf{texture}, defined as surface smoothness or roughness, it is necessary to consider pixel grey levels.
It captures patterns, repetitiveness, and granularity of a region.
There are various texture features, including statistical, structural, and spectral ones.

\noindent \textbf{Statistical features} are retrieved from the normalised region histogram and grey level distribution variance.
If $z$ represents a random variable denoting grey levels and $p(z_i)$, where $i=0,1,\dots,L-1$, represents the histogram, it is possible to define the $n^{th}$ moment of $z$:

\begin{equation}
    \mu_n (z) = \sum_{k=0}^{L-1}(z_i-m)^np(z_i), \qquad m = \sum_{i=0}^{L-1}z_ip(z_i)
\end{equation}

The main statistical features are:

\begin{itemize}
    \item \textbf{roughness:}
    \[ R = 1 - \dfrac{1}{1+\sigma^2 (z)} \]
    It equals 0 for uniform objects and tends to 1 for larger variance values;
    \item \textbf{uniformity:}
    \[ U = \sum_{i=0}^{L-1} p^2 (z_i) \]
    It reaches the maximum when there is only one grey level in the image;
    \item \textbf{average entropy:}
    \[ e = - \sum_{i=0}^{L-1}p(z_i) \log_2 p(z_i) \]
    In a constant image, it equals 0.
\end{itemize}

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\linewidth]{immagini/texture.jpg}
    \caption{Statistical features of three images with different textures.}
    \label{fig:texture}
\end{figure}

\noindent Standard deviation and, therefore, roughness allow for the identification of smooth regions; highest uniformity is reached when entropy is lowest.

The main limitation of the statistical approach is that the histogram is not a unique representation of an image; therefore, if two distinct images share the same histogram, their statistical features will be equal.
This approach does not consider the spatial information of the texture.

\subsection{Co-occurrence matrix}

In order to take into account the spatial information of the texture, it is possible to consider a displacement vector $\vect{P}$ to generate a \textbf{co-occurrence matrix}.
In this matrix, each entry $a_{ij}$ represents the number of times a pixel with a grey level $z_i$ is in a relative position $\vect{P}$ with respect to a pixel with a grey level $z_j$.
The matrix is then normalised so that the entries represent probabilities.
Usually, a number of displacement vectors are considered to obtain a set of co-occurrence matrices that become descriptors from which it is possible to extract features of the texture.
The more similar the textures in two different images are, the more similar their matrices become.