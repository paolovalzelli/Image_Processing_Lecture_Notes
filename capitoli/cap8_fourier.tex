\chapter{Fourier in Image Processing}
\label{ch:fourier}

\section{Fourier Transform}

\subsection{Spatial and frequency domains}

An important tool in image processing is the \textbf{Fourier transform}, utilised to decompose an image into its sine and cosine components, enabling image filtering, reconstruction, and compression.
The output of the transformation is the \textbf{Fourier spectrum} of the image in the \textit{frequency domain}, where each point represents the signal amplitude at that specific frequency.
Regular signals in the \textbf{spatial domain} produce distinct signals in the frequency domain corresponding to the spacing.
Each term of the series in the frequency domain represents the importance of that spatial frequency within the image.

The most common operations enabled by the Fourier transform in image processing are:

\begin{itemize}
    \item \textbf{Fourier analysis}: A signal is decomposed into its constituent sinusoids of varying frequencies;
    \item \textbf{Fourier synthesis}: Simple oscillating signals are combined to generate complex 2-dimensional distributions of grey levels;
    \item \textbf{Fourier spectrum}: A distribution of amplitudes for the various frequencies composing a complex signal is obtained.
\end{itemize}

\subsection{Image decomposition}

A 2-dimensional distribution of grey levels can be decomposed into a (possibly infinite) set of sine functions with varying amplitudes and frequencies.

A sine wave consists of a single frequency, thus its spectrum is a single point.
A periodic wave can be decomposed into a sum of sine waves, whereas a square wave requires an infinite number of sine waves for representation.
White noise is characterised by a \textit{white spectrum}; that is, a spectrum where every frequency has equal intensity.

\section{Fourier Transform Definitions}

The output of the \textbf{Fourier transform} is a complex number that can be displayed as a pair of images representing either the real and imaginary parts, or the magnitude and phase.
Usually, the latter is preferred in image processing, as the primary focus is often the magnitude of each specific frequency.

\subsection{Direct and inverse transform}

The \textbf{direct transform} and the \textbf{inverse transform} of a 1-dimensional continuous function are defined by:

\begin{align}
    F(u) & = \int_{-\infty}^{+\infty} f(x) e^{-2\pi \iu ux} \, dx \\
    f(x) & = \int_{-\infty}^{+\infty} F(u) e^{2\pi \iu ux} \, du
\end{align}

For 2-dimensional signals, such as images, the definitions become:

\begin{align}
    F(u,v) = \fourier{f(x,y)} & = \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty}f(x,y) e^{-2\pi \iu (ux + vy)} \, dx \, dy \\
    f(x,y) = \ifourier{F(u,v)} & = \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty}F(u,v) e^{2\pi \iu (ux + vy)} \, du \, dv
\end{align}

\subsection{Discrete Fourier transform}

The \textbf{discrete Fourier transform} (DFT) is utilised for images, as they are discrete distributions of values in a 2D space.
The number of frequencies forming the image spectrum is limited by the number of pixels in the original spatial domain image:

\begin{align}
    F(u) & = \frac{1}{M} \sum_{x = 0}^{M - 1} f(x) e^{-2\pi \iu u \frac{x}{M}} \quad \text{for } u = 0,1,\dots,M \\
    f(x) & = \frac{1}{M} \sum_{x = 0}^{M - 1}F(u) e^{2\pi \iu u \frac{x}{M}} \quad \text{for } x = 0,1,\dots,M
\end{align}

The sampling step in the frequency domain is given by the pixel size in the spatial domain: $\Delta u = (M \Delta x)^{-1}$.

By utilising Euler's formula, the complex exponential functions can be replaced by trigonometric functions:

\begin{equation}
    F(u) = \frac{1}{M} \sum_{x = 0}^{M - 1} f(x) \left[ \dfrac{\cos (2\pi ux) - \iu \sin(2\pi ux)}{M} \right] \quad \text{for } u = 0,1,\dots,M
\end{equation}

The DFTs in 2 dimensions are defined as:

\begin{align}
    F(u,v) & = \frac{1}{M \cdot N} \sum_{x = 0}^{M - 1} \sum_{y = 0}^{N - 1} f(x,y) e^{-2\pi \iu \left( u \frac{x}{M} + v \frac{y}{N} \right)} \\
    f(x,y) & = \frac{1}{M \cdot N} \sum_{x = 0}^{M - 1} \sum_{y = 0}^{N - 1} F(u,v) e^{2\pi \iu \left( u \frac{x}{M} + v \frac{y}{N} \right)}
\end{align}

The Fourier transform at the origin $(u,v) = (0,0)$, referred to as the \textit{DC component}, is equal to the average of the image grey levels:

\begin{equation}
    F(0,0) = \frac{1}{M \cdot N} \sum_{x = 0}^{M - 1} \sum_{y = 0}^{N - 1} f(x,y)
\end{equation}

The name suggests that this value does not undergo oscillations.

\subsection{Fourier spectrum}

The DC component is shifted to the centre of the frequency spectrum and is by far the largest component; therefore, to correctly display it, the logarithm is shown to compress the range of values. 
Another solution is to exclude the central pixel from the spectrum.
The \textbf{Fourier spectrum} is a digital image in which every pixel displays the magnitude associated with that frequency.

By observing only the magnitude, information regarding the spatial position of objects is lost.
It is possible to associate the frequencies showcased in the spectrum with patterns of intensity variations in an image:

\begin{itemize}
    \item Low frequencies correspond to slowly varying components of an image;
    \item High frequencies correspond to sharp changes in the image, such as edges and noise.
\end{itemize}

Notably, in images with defined geometry, certain structures can be highlighted in the spectrum.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\linewidth]{immagini/fourier_spectrum.png}
    \caption{Example of an image and its Fourier spectrum.}
    \label{fig:fourier_spectrum}
\end{figure}

\section{Fourier Transform Properties}

The Fourier transforms of 2D signals are characterised by:

\begin{itemize}
    \item \textbf{symmetry}: $|F(u,v)| = |F(-u, -v)|$;
    \item \textbf{distributivity}: The Fourier transform is distributive over addition but not over multiplication:
    \begin{align}
        \fourier{f_1 (x,y) + f_2 (x,y)} & = \fourier{f_1 (x,y)} + \fourier{f_2 (x,y)} \\
        \fourier{f_1 (x,y) \cdot f_2 (x,y)} & \ne \fourier{f_1 (x,y)} \cdot \fourier{f_2 (x,y)}
    \end{align}
    \item \textbf{rotation}: A rotation of the image results in an equivalent rotation of its Fourier transform:
    \begin{equation}
        f(r, \theta + \theta_0) \Longleftrightarrow F(\omega, \phi + \theta_0)
    \end{equation}
    \item \textbf{scaling}: Scaling in the spatial domain determines a scaling of the Fourier transform.
    \begin{equation}
        f(x,y) \longrightarrow f(M_x \cdot x, M_y \cdot y) \Longrightarrow F(u,v) \longrightarrow \dfrac{F \left( \dfrac{u}{M_x}, \dfrac{v}{M_y} \right)}{| M_x \cdot M_y |}
    \end{equation}
\end{itemize}

\subsection{Distributivity}

Thanks to the property of \textbf{distributivity}, it is possible to highlight certain spectrum components and remove unwanted features, allowing the inverse transform to filter them out.
Some frequencies can be filtered out, providing a different strategy for noise reduction when spatial domain methods are ineffective.
For example, the central part of the spectrum is responsible for the general grey level appearance of an image, while the outer region contains the information regarding the details.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.65\linewidth]{immagini/distributivity.png}
    \caption{Example of application of the distributivity property of Fourier transforms.}
    \label{fig:distributivity}
\end{figure}

\section{Convolution Theorem}

The \textbf{convolution theorem} expresses the relationship between the  spatial and frequency domains: convolution in the spatial domain between an image and a kernel is equivalent to multiplication in the frequency domain between the spectrum and a filter obtained as the Fourier transform of the kernel.
Given the convolution of the image $f(x,y)$ and a kernel $h(x,y)$:

\begin{equation}
    f(x,y) \ast h(x,y) = \sum_{x=0}^{M-1} \sum_{y=0}^{N-1} f(m,n) \cdot h(x-m, y-n)
\end{equation}

Expressing with $F(u,v)$ and $H(u,v)$ the Fourier transforms of the image and kernel, it holds:

\begin{equation}
    f(x,y) \ast h(x,y) \Longleftrightarrow F(u,v) \cdot H(u,v)
\end{equation}

This theorem exploits the distributivity property of the Fourier transform, as it is possible to multiply the spectrum by a binary mask in the frequency domain to effectively filter out unwanted frequencies.
The computational cost of this operation is that of a multiplication (one calculation per pixel), as opposed to $M^2$ for spatial convolution.
This does not account for the cost of calculating both direct and inverse transforms.
The main advantage offered by the theorem is the wider variety of operations that can be carried out in the frequency domain.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.65\linewidth]{immagini/convolution_theorem.png}
    \caption{Convolution theorem visualised.}
    \label{fig:convolution_theorem}
\end{figure}

\section{Frequency Filters}

Applying a \textbf{low-pass filter} to the image spectrum and subsequently taking the inverse transform can cut high frequencies, achieving a smoothing effect that blurs edges and reduces noise.
Conversely, applying a \textbf{high-pass filter} highlights edges while losing information about uniform regions, yielding a result similar to edge detection in the spatial domain.
It is possible to cut out both high and low frequencies by applying a \textbf{band-pass filter}.

This similarity to local operations explains why they are often referred to as \textit{filters}.

\subsection{Performance in image filtering}

Linear spatial filtering can be performed both in the spatial domain, by applying a convolution with a spatial operator, and in the frequency domain, by multiplying the Fourier transform of the image and filter and then computing the inverse transform.
The filter may be simpler to specify or compute in one of the two domains.
The Fourier transform allows for the isolation of a particular frequency range and for high-precision filtering.

Noise reduction can be achieved by manually constructing the appropriate filter to be applied to the image's Fourier transform.

\subsection{Ideal filters}

These filters are characterised by a sharp transition between 1 and 0 at a specific \textit{cutoff frequency} $D_0$.

For example, an ideal low-pass filter is described by:

\begin{equation}
    H(u,v) = \begin{cases}
        1, & \text{ if } D(u,v) \le D_0 \\ 0, & \text{ if } D(u,v) > D_0
    \end{cases} \qquad D(u,v) = \sqrt{\left( u - \dfrac{M}{2} \right)^2 + \left( v - \dfrac{N}{2} \right)^2}  
\end{equation}

The main limitation of ideal filters is the creation of artifacts in processed images, such as the typical \textit{ringing effect}; consequently, they are rarely utilised.

\subsection{Common filters}

Compared to ideal ones, \textbf{common filters} exhibit a smoother transition between 1 and 0.
Figure~\ref{fig:common_filters} presents some of the most common high-pass filters.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\linewidth]{immagini/common_filters.png}
    \caption{Shape of some of the most common filters.}
    \label{fig:common_filters}
\end{figure}

The most common low-pass filter, the \textbf{Butterworth low-pass filter}, has a shape approximating a Gaussian distribution.
It is used to avoid the ringing effect.

If background noise has a well-defined structure, especially a periodic signal, it is possible to significantly reduce it by cutting out specific frequencies, whereas achieving similar results in the spatial domain would be impossible.

Figure~\ref{fig:moon} presents a clear example of structured noise reduction using a properly crafted filter.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.5\linewidth]{immagini/moon.png}
    \caption{Noise reduction from a lunar orbital image recorded in 1966.}
    \label{fig:moon}
\end{figure}